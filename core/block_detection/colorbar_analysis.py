"""
æ™ºèƒ½è‰²æ¿åˆ†ææµæ°´çº¿
é«˜çº§ä¸‰æ­¥éª¤å·¥ä½œæµç¨‹ï¼Œç”¨äºè‰²æ¿æ£€æµ‹å’Œé¢œè‰²åˆ†æï¼š
1. YOLOæ£€æµ‹è‰²æ¿åŒºåŸŸ
2. åœ¨æ¯ä¸ªè‰²æ¿å†…è¿›è¡Œå—æ£€æµ‹
3. ä½¿ç”¨CMYKè½¬æ¢å’ŒDelta Eè®¡ç®—è¿›è¡Œå•ä¸ªé¢œè‰²å—åˆ†æ

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- åŒ…å«åŸå§‹åˆ†å‰²çš„è‰²æ¿å›¾åƒ
- å¯†é›†ã€æœ‰ç»„ç»‡çš„ç»“æœæ˜¾ç¤º
- ä½¿ç”¨ICCé…ç½®æ–‡ä»¶è¿›è¡ŒCMYKé¢œè‰²è½¬æ¢
- ä¸æ ‡å‡†çœŸå€¼é¢œè‰²æ¯”è¾ƒï¼ŒåŒ…å«Delta Eè®¡ç®—
"""

import cv2
import numpy as np
from PIL import Image

from ..color.ground_truth_checker import ground_truth_checker
from .blocks_detect import detect_blocks
from .color_analysis import analyze_colorbar_blocks
from .yolo_show import detect_colorbars_yolo, load_yolo_model


def extract_blocks_from_colorbar(
    colorbar_segment: np.ndarray,
    area_threshold: int = 50,
    aspect_ratio_threshold: float = 0.3,
    min_square_size: int = 5,
) -> tuple[np.ndarray, list[np.ndarray], int]:
    """
    ä¸“é—¨å¯¹è‰²æ¿ç‰‡æ®µåº”ç”¨å—æ£€æµ‹ä»¥æå–å•ä¸ªé¢œè‰²è‰²å—ã€‚

    Args:
        colorbar_segment: è‰²æ¿å›¾åƒç‰‡æ®µï¼ˆBGRæ ¼å¼ï¼‰
        area_threshold: æ£€æµ‹å—çš„æœ€å°é¢ç§¯
        aspect_ratio_threshold: å—çš„æœ€å°é•¿å®½æ¯”
        min_square_size: æ£€æµ‹å—çš„æœ€å°å®½åº¦å’Œé«˜åº¦ï¼ˆåƒç´ ï¼‰

    Returns:
        è¿”å›å…ƒç»„ï¼š(æ ‡æ³¨è‰²æ¿, é¢œè‰²å—åˆ—è¡¨, å—æ•°é‡)
    """
    if colorbar_segment.size == 0:
        return colorbar_segment, [], 0

    # ä½¿ç”¨ç°æœ‰çš„å—æ£€æµ‹å‡½æ•°ï¼Œè°ƒæ•´å‚æ•°é€‚ç”¨äºè‰²æ¿
    result_image, block_images, block_count = detect_blocks(
        colorbar_segment,
        output_dir=None,  # ä¸ä¿å­˜æ–‡ä»¶
        area_threshold=area_threshold,
        aspect_ratio_threshold=aspect_ratio_threshold,
        min_square_size=min_square_size,
        return_individual_blocks=True,
    )

    return result_image, block_images, block_count


def enhance_with_ground_truth_comparison(block_analyses: list[dict]) -> list[dict]:
    """
    é€šè¿‡æ ‡å‡†çœŸå€¼é¢œè‰²æ¯”è¾ƒå’ŒDelta Eè®¡ç®—å¢å¼ºå—åˆ†æã€‚

    Args:
        block_analyses: å—åˆ†æå­—å…¸åˆ—è¡¨

    Returns:
        å¢å¼ºçš„åŒ…å«æ ‡å‡†çœŸå€¼æ¯”è¾ƒæ•°æ®çš„å—åˆ†æ
    """
    enhanced_analyses = []

    for analysis in block_analyses:
        # å¦‚æœåˆ†æä¸­æœ‰é”™è¯¯ï¼Œè·³è¿‡
        if "error" in analysis:
            enhanced_analyses.append(analysis)
            continue

        # æå–ä¸»è¦RGBé¢œè‰²
        primary_rgb = analysis.get("primary_color_rgb")
        if not primary_rgb:
            enhanced_analyses.append(analysis)
            continue

        # æŸ¥æ‰¾æœ€æ¥è¿‘çš„æ ‡å‡†çœŸå€¼é¢œè‰²å¹¶è®¡ç®—Delta E
        closest_gt_color, delta_e = ground_truth_checker.find_closest_color(primary_rgb)

        # ä½¿ç”¨æ ‡å‡†çœŸå€¼æ¯”è¾ƒå¢å¼ºåˆ†æ
        enhanced_analysis = analysis.copy()
        enhanced_analysis.update(
            {
                "ground_truth_comparison": {
                    "closest_color": {
                        "id": closest_gt_color.id,
                        "name": closest_gt_color.name,
                        "cmyk": closest_gt_color.cmyk,
                        "rgb": closest_gt_color.rgb,
                        "lab": closest_gt_color.lab,
                    }
                    if closest_gt_color
                    else None,
                    "delta_e": delta_e,
                    "accuracy_level": ground_truth_checker._get_accuracy_level(delta_e),
                    "is_acceptable": delta_e
                    < 3.0,  # Delta E < 3 æ˜¯å¯æ¥å—é¢œè‰²çš„é˜ˆå€¼
                }
            }
        )

        enhanced_analyses.append(enhanced_analysis)

    return enhanced_analyses


def colorbar_analysis_pipeline(
    pil_image: Image.Image,
    # YOLOå‚æ•°
    confidence_threshold: float = 0.5,
    box_expansion: int = 10,
    model_path: str = None,
    # å—æ£€æµ‹å‚æ•°
    block_area_threshold: int = 50,
    block_aspect_ratio: float = 0.3,
    min_square_size: int = 5,
    # é¢œè‰²åˆ†æå‚æ•°
    shrink_size: tuple[int, int] = (30, 30),
) -> dict:
    """
    å®Œæ•´çš„æ™ºèƒ½è‰²æ¿åˆ†ææµæ°´çº¿ã€‚

    Args:
        pil_image: è¾“å…¥PILå›¾åƒ
        confidence_threshold: YOLOç½®ä¿¡åº¦é˜ˆå€¼
        box_expansion: YOLOæ¡†æ‰©å±•åƒç´ 
        model_path: YOLOæ¨¡å‹è·¯å¾„
        block_area_threshold: è‰²æ¿å†…å—çš„æœ€å°é¢ç§¯
        block_aspect_ratio: å—çš„æœ€å°é•¿å®½æ¯”
        min_square_size: æ£€æµ‹å—çš„æœ€å°å®½åº¦å’Œé«˜åº¦ï¼ˆåƒç´ ï¼‰
        shrink_size: ä¸ºé¢œè‰²åˆ†æç¼©å°å—çš„å°ºå¯¸

    Returns:
        åŒ…å«å®Œæ•´åˆ†æç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬åŸå§‹è‰²æ¿ç‰‡æ®µ
    """
    if pil_image is None:
        return {"error": "No image provided"}

    try:
        # æ­¥éª¤1ï¼šYOLOè‰²æ¿æ£€æµ‹
        print("Step 1: Detecting colorbars with YOLO...")
        model = load_yolo_model(model_path)

        # å°†PILè½¬æ¢ä¸ºOpenCV
        opencv_image = np.array(pil_image)
        if len(opencv_image.shape) == 3:
            opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_RGB2BGR)

        # è¿è¡ŒYOLOæ£€æµ‹
        (
            annotated_image,
            colorbar_boxes,
            confidences,
            colorbar_segments,
        ) = detect_colorbars_yolo(
            opencv_image,
            model,
            box_expansion=box_expansion,
            confidence_threshold=confidence_threshold,
        )

        if len(colorbar_segments) == 0:
            return {
                "error": "No colorbars detected",
                "annotated_image": Image.fromarray(
                    cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
                ),
                "step_completed": 1,
            }

        # æ­¥éª¤2ï¼šåœ¨æ¯ä¸ªè‰²æ¿å†…è¿›è¡Œå—æ£€æµ‹
        print(
            f"Step 2: Detecting blocks within {len(colorbar_segments)} colorbar(s)..."
        )
        colorbar_results = []

        for i, (segment, confidence, box) in enumerate(
            zip(colorbar_segments, confidences, colorbar_boxes, strict=False)
        ):
            colorbar_id = i + 1
            print(f"  Processing colorbar {colorbar_id}/{len(colorbar_segments)}...")

            # ä»æ­¤è‰²æ¿æå–å—
            (
                segmented_colorbar,
                color_blocks,
                block_count,
            ) = extract_blocks_from_colorbar(
                segment,
                area_threshold=block_area_threshold,
                aspect_ratio_threshold=block_aspect_ratio,
                min_square_size=min_square_size,
            )

            # æ­¥éª¤3ï¼šåˆ†ææ¯ä¸ªå—ä¸­çš„é¢œè‰²
            print(
                f"  Step 3: Analyzing {block_count} color blocks in colorbar {colorbar_id}..."
            )
            block_analyses = []

            if block_count > 0:
                block_analyses = analyze_colorbar_blocks(
                    color_blocks, shrink_size, colorbar_id=colorbar_id
                )

                # æ­¥éª¤4ï¼šè®¡ç®—ä¸æ ‡å‡†çœŸå€¼é¢œè‰²çš„Delta E
                print("  Step 4: Calculating delta E against ground truth colors...")
                block_analyses = enhance_with_ground_truth_comparison(block_analyses)

            # å°†ç‰‡æ®µè½¬æ¢ä¸ºPILä»¥ä¾¿æ›´å¥½çš„ç•Œé¢é›†æˆ
            original_segment_pil = None
            segmented_colorbar_pil = None

            if segment.size > 0:
                original_segment_pil = Image.fromarray(
                    cv2.cvtColor(segment, cv2.COLOR_BGR2RGB)
                )
            if segmented_colorbar.size > 0:
                segmented_colorbar_pil = Image.fromarray(
                    cv2.cvtColor(segmented_colorbar, cv2.COLOR_BGR2RGB)
                )

            colorbar_result = {
                "colorbar_id": colorbar_id,
                "confidence": confidence,
                "bounding_box": box,
                "original_segment": segment,  # åŸå§‹OpenCVæ ¼å¼
                "original_segment_pil": original_segment_pil,  # ç”¨äºæ˜¾ç¤ºçš„PILæ ¼å¼
                "segmented_colorbar": segmented_colorbar,  # OpenCVæ ¼å¼
                "segmented_colorbar_pil": segmented_colorbar_pil,  # ç”¨äºæ˜¾ç¤ºçš„PILæ ¼å¼
                "color_blocks": color_blocks,
                "block_count": block_count,
                "block_analyses": block_analyses,
            }

            colorbar_results.append(colorbar_result)

        return {
            "success": True,
            "annotated_image": annotated_image,
            "colorbar_count": len(colorbar_segments),
            "colorbar_results": colorbar_results,
            "total_blocks": sum(result["block_count"] for result in colorbar_results),
            "step_completed": 3,
        }

    except Exception as e:
        return {
            "error": f"Error in colorbar analysis pipeline: {str(e)}",
            "step_completed": 0,
        }


def colorbar_analysis_for_gradio(
    pil_image: Image.Image,
    confidence_threshold: float = 0.5,
    box_expansion: int = 10,
    block_area_threshold: int = 50,
    block_aspect_ratio: float = 0.3,
    min_square_size: int = 5,
    shrink_size: tuple[int, int] = (30, 30),
) -> tuple[Image.Image, list[dict], str, int]:
    """
    ä¸ºGradioç•Œé¢ä¼˜åŒ–çš„è‰²æ¿åˆ†ææµæ°´çº¿åŒ…è£…å™¨ã€‚

    Returns:
        è¿”å›å…ƒç»„ï¼š(
            æ ‡æ³¨å›¾åƒ,
            åŒ…å«åŸå§‹ç‰‡æ®µçš„è‰²æ¿æ•°æ®,
            åˆ†ææŠ¥å‘Š,
            æ‰¾åˆ°çš„æ€»å—æ•°
        )
    """
    # è¿è¡Œå®Œæ•´çš„è‰²æ¿åˆ†ææµæ°´çº¿
    result = colorbar_analysis_pipeline(
        pil_image,
        confidence_threshold=confidence_threshold,
        box_expansion=box_expansion,
        block_area_threshold=block_area_threshold,
        block_aspect_ratio=block_aspect_ratio,
        min_square_size=min_square_size,
        shrink_size=shrink_size,
    )

    if "error" in result:
        error_img = pil_image if pil_image else None
        return error_img, [], f"âŒ {result['error']}", 0

    if not result.get("success", False):
        return pil_image, [], "âŒ Analysis failed", 0

    # å°†æ ‡æ³¨å›¾åƒè½¬æ¢ä¸ºPIL
    annotated_pil = Image.fromarray(
        cv2.cvtColor(result["annotated_image"], cv2.COLOR_BGR2RGB)
    )

    # å‡†å¤‡åŒ…å«åŸå§‹ç‰‡æ®µçš„è‰²æ¿æ•°æ®
    colorbar_data = []

    # æ„å»ºåŒ…å«Delta Eç»Ÿè®¡ä¿¡æ¯çš„ç»¼åˆåˆ†ææŠ¥å‘Š
    report = "ğŸ¯ Intelligent Colorbar Analysis Results\n"
    report += "=" * 50 + "\n\n"
    report += "ğŸ“Š Summary:\n"
    report += f"  â€¢ Colorbars detected: {result['colorbar_count']}\n"
    report += f"  â€¢ Total color blocks: {result['total_blocks']}\n"

    # è®¡ç®—Delta Eç»Ÿè®¡ä¿¡æ¯
    all_delta_e_values = []
    acceptable_count = 0
    total_analyzed = 0

    for colorbar_result in result["colorbar_results"]:
        for analysis in colorbar_result["block_analyses"]:
            if "error" not in analysis:
                ground_truth_data = analysis.get("ground_truth_comparison")
                if ground_truth_data:
                    delta_e = ground_truth_data.get("delta_e", 0)
                    all_delta_e_values.append(delta_e)
                    total_analyzed += 1
                    if delta_e < 3.0:
                        acceptable_count += 1

    # å¦‚æœæœ‰Delta Eå€¼ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if all_delta_e_values:
        import statistics

        avg_delta_e = statistics.mean(all_delta_e_values)
        max_delta_e = max(all_delta_e_values)
        min_delta_e = min(all_delta_e_values)
        accuracy_percentage = (acceptable_count / total_analyzed) * 100

        report += f"  â€¢ Average Î”E: {avg_delta_e:.2f}\n"
        report += f"  â€¢ Î”E Range: {min_delta_e:.2f} - {max_delta_e:.2f}\n"
        report += f"  â€¢ Acceptable colors (Î”E < 3.0): {acceptable_count}/{total_analyzed} ({accuracy_percentage:.1f}%)\n"

    report += "\n"

    # ä¸ºæ¯ä¸ªè‰²æ¿ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    for colorbar_result in result["colorbar_results"]:
        colorbar_id = colorbar_result["colorbar_id"]
        confidence = colorbar_result["confidence"]
        block_count = colorbar_result["block_count"]

        # å°†é¢œè‰²å—è½¬æ¢ä¸ºPIL
        color_blocks_pil = []
        for block in colorbar_result["color_blocks"]:
            if block.size > 0:
                block_pil = Image.fromarray(cv2.cvtColor(block, cv2.COLOR_BGR2RGB))
                color_blocks_pil.append(block_pil)

        # åˆ›å»ºåŒ…å«åŸå§‹ç‰‡æ®µçš„è‰²æ¿æ•°æ®æ¡ç›®
        colorbar_entry = {
            "colorbar_id": colorbar_id,
            "confidence": confidence,
            "original_colorbar": colorbar_result[
                "original_segment_pil"
            ],  # âœ¨ åŸå§‹ç‰‡æ®µ
            "segmented_colorbar": colorbar_result["segmented_colorbar_pil"],
            "color_blocks": color_blocks_pil,
            "block_count": block_count,
            "block_analyses": colorbar_result["block_analyses"],
        }
        colorbar_data.append(colorbar_entry)

        # å‘æŠ¥å‘Šæ·»åŠ å¯†é›†çš„è‰²æ¿éƒ¨åˆ†
        report += f"ğŸ¨ Colorbar {colorbar_id} (confidence: {confidence:.2f}):\n"
        report += f"  â€¢ Color blocks found: {block_count}\n"

        if block_count > 0:
            report += "  â€¢ Colors with CMYK values and delta E:\n"

            # ä¸ºæ¯ä¸ªå—æ·»åŠ ç®€æ´çš„é¢œè‰²åˆ†æ
            for analysis in colorbar_result["block_analyses"]:
                if "error" not in analysis:
                    block_id = analysis.get("block_id", "?")
                    primary_rgb = analysis["primary_color_rgb"]
                    primary_cmyk = analysis["primary_color_cmyk"]
                    primary_hex = (
                        f"#{primary_rgb[0]:02x}{primary_rgb[1]:02x}{primary_rgb[2]:02x}"
                    )

                    report += f"    {colorbar_id}.{block_id}: {primary_hex} "
                    report += f"(C={primary_cmyk[0]}% M={primary_cmyk[1]}% Y={primary_cmyk[2]}% K={primary_cmyk[3]}%)"

                    # å¦‚æœå¯ç”¨ï¼Œæ·»åŠ Delta Eä¿¡æ¯
                    ground_truth_data = analysis.get("ground_truth_comparison")
                    if ground_truth_data:
                        delta_e = ground_truth_data.get("delta_e", 0)
                        accuracy_level = ground_truth_data.get(
                            "accuracy_level", "Unknown"
                        )
                        closest_color = ground_truth_data.get("closest_color")

                        report += f" â†’ Î”E: {delta_e:.2f} ({accuracy_level})"
                        if closest_color:
                            report += f" vs {closest_color['name']}"

                    report += "\n"

        report += "\n"

    return (annotated_pil, colorbar_data, report, result["total_blocks"])


# å‘åå…¼å®¹æ€§åˆ«å
enhanced_colorbar_analysis = colorbar_analysis_pipeline
enhanced_colorbar_analysis_from_pil = colorbar_analysis_for_gradio
