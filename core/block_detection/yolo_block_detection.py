"""
YOLOè‰²å—æ£€æµ‹æ¨¡å—
ä½¿ç”¨è®­ç»ƒå¥½çš„YOLOæ¨¡å‹ç›´æ¥æ£€æµ‹è‰²å—
é‡æ„ä¸ºç±»ç»“æ„ï¼Œæä¾›æ›´å¥½çš„æ¨¡å‹ç®¡ç†å’Œæ£€æµ‹åŠŸèƒ½
"""

import os
import cv2
import numpy as np
import warnings
from typing import List, Dict, Tuple, Optional
from PIL import Image
from ultralytics import YOLO


class YOLOBlockDetector:
    """YOLOè‰²å—æ£€æµ‹å™¨ç±»"""
    
    def __init__(self, model_path: str = None):
        """
        åˆå§‹åŒ–YOLOè‰²å—æ£€æµ‹å™¨
        
        Args:
            model_path: YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        self.model = None
        self.model_path = model_path or "core/block_detection/weights/best.pt"
        self.is_loaded = False
        
        # å°è¯•åŠ è½½æ¨¡å‹
        self.load_model()
    
    def load_model(self) -> bool:
        """
        åŠ è½½YOLOæ¨¡å‹
        
        Returns:
            bool: æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if not os.path.exists(self.model_path):
                print(f"è­¦å‘Š: YOLOæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                print("è¯·ç¡®ä¿å·²è®­ç»ƒå¥½çš„YOLOæ¨¡å‹æ–‡ä»¶å­˜åœ¨äºæŒ‡å®šè·¯å¾„")
                self.is_loaded = False
                return False
            
            self.model = YOLO(self.model_path)
            self.is_loaded = True
            print(f"YOLOæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            return True
            
        except Exception as e:
            print(f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
            self.is_loaded = False
            return False
    
    def detect_blocks(
        self, 
        image: np.ndarray,
        confidence_threshold: float = 0.5,
        min_area: int = 50,
        max_detections: int = 50
    ) -> List[Dict]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„è‰²å—
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            min_area: æœ€å°è‰²å—é¢ç§¯
            max_detections: æœ€å¤§æ£€æµ‹æ•°é‡
            
        Returns:
            List[Dict]: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                - bbox: [x1, y1, x2, y2] è¾¹ç•Œæ¡†åæ ‡
                - confidence: ç½®ä¿¡åº¦
                - class_id: ç±»åˆ«ID
                - class_name: ç±»åˆ«åç§°
                - area: åŒºåŸŸé¢ç§¯
                - center: (x, y) ä¸­å¿ƒç‚¹åæ ‡
        """
        if not self.is_loaded:
            print("é”™è¯¯: YOLOæ¨¡å‹æœªåŠ è½½")
            return []
        
        if image is None or image.size == 0:
            print("é”™è¯¯: è¾“å…¥å›¾åƒä¸ºç©º")
            return []
        
        try:
            # è¿›è¡Œæ£€æµ‹
            results = self.model(
                image,
                conf=confidence_threshold,
                max_det=max_detections,
                verbose=False
            )
            
            detections = []
            
            # è§£ææ£€æµ‹ç»“æœ
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
                    confidences = result.boxes.conf.cpu().numpy()
                    classes = result.boxes.cls.cpu().numpy() if result.boxes.cls is not None else np.zeros(len(boxes))
                    
                    for i, box in enumerate(boxes):
                        x1, y1, x2, y2 = box.astype(int)
                        confidence = float(confidences[i])
                        class_id = int(classes[i])
                        
                        # è®¡ç®—é¢ç§¯
                        width = x2 - x1
                        height = y2 - y1
                        area = width * height
                        
                        # æ£€æŸ¥æœ€å°é¢ç§¯é˜ˆå€¼
                        if area < min_area:
                            continue
                        
                        center_x = x1 + width // 2
                        center_y = y1 + height // 2
                        
                        # è·å–ç±»åˆ«åç§°
                        class_name = self._get_class_name(class_id)
                        
                        detection = {
                            'bbox': [x1, y1, x2, y2],
                            'confidence': confidence,
                            'class_id': class_id,
                            'class_name': class_name,
                            'area': area,
                            'center': (center_x, center_y),
                            'width': width,
                            'height': height
                        }
                        
                        detections.append(detection)
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x['confidence'], reverse=True)
            
            return detections
            
        except Exception as e:
            print(f"YOLOæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _get_class_name(self, class_id: int) -> str:
        """
        æ ¹æ®ç±»åˆ«IDè·å–ç±»åˆ«åç§°
        
        Args:
            class_id: ç±»åˆ«ID
            
        Returns:
            str: ç±»åˆ«åç§°
        """
        # æ ¹æ®å®é™…çš„YOLOæ¨¡å‹ç±»åˆ«è®¾ç½®
        class_names = {
            0: 'color_block',
            1: 'color_patch',
            2: 'color_strip'
        }
        
        return class_names.get(class_id, f'class_{class_id}')
    
    def visualize_detections(
        self, 
        image: np.ndarray, 
        detections: List[Dict],
        show_confidence: bool = True,
        show_class: bool = True,
        line_thickness: int = 2
    ) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šå¯è§†åŒ–æ£€æµ‹ç»“æœ
        
        Args:
            image: åŸå§‹å›¾åƒ
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            show_confidence: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
            show_class: æ˜¯å¦æ˜¾ç¤ºç±»åˆ«åç§°
            line_thickness: è¾¹ç•Œæ¡†çº¿æ¡ç²—ç»†
            
        Returns:
            np.ndarray: æ ‡æ³¨åçš„å›¾åƒ
        """
        if image is None or len(detections) == 0:
            return image.copy() if image is not None else np.zeros((100, 100, 3), dtype=np.uint8)
        
        annotated_image = image.copy()
        
        for i, detection in enumerate(detections):
            x1, y1, x2, y2 = detection['bbox']
            confidence = detection['confidence']
            class_name = detection['class_name']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), line_thickness)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            label_parts = []
            if show_class:
                label_parts.append(class_name)
            if show_confidence:
                label_parts.append(f"{confidence:.2f}")
            
            if label_parts:
                label = " ".join(label_parts)
                
                # è®¡ç®—æ–‡æœ¬å¤§å°
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.5
                thickness = 1
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, font, font_scale, thickness
                )
                
                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                cv2.rectangle(
                    annotated_image,
                    (x1, y1 - text_height - baseline - 5),
                    (x1 + text_width + 5, y1),
                    (0, 255, 0),
                    -1
                )
                
                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(
                    annotated_image,
                    label,
                    (x1 + 2, y1 - baseline - 2),
                    font,
                    font_scale,
                    (255, 255, 255),  # ç™½è‰²æ–‡æœ¬
                    thickness
                )
        
        return annotated_image
    
    def extract_color_blocks(
        self, 
        image: np.ndarray, 
        detections: List[Dict],
        padding: int = 5
    ) -> List[np.ndarray]:
        """
        ä»æ£€æµ‹ç»“æœä¸­æå–è‰²å—å›¾åƒ
        
        Args:
            image: åŸå§‹å›¾åƒ
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            padding: è¾¹ç•Œæ¡†æ‰©å±•åƒç´ æ•°
            
        Returns:
            List[np.ndarray]: æå–çš„è‰²å—å›¾åƒåˆ—è¡¨
        """
        if image is None or len(detections) == 0:
            return []
        
        color_blocks = []
        h, w = image.shape[:2]
        
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            
            # æ·»åŠ paddingå¹¶ç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
            x1 = max(0, x1 - padding)
            y1 = max(0, y1 - padding)
            x2 = min(w, x2 + padding)
            y2 = min(h, y2 + padding)
            
            # æå–è‰²å—
            color_block = image[y1:y2, x1:x2]
            
            if color_block.size > 0:
                color_blocks.append(color_block)
        
        return color_blocks
    
    def detect_and_extract(
        self,
        image: np.ndarray,
        confidence_threshold: float = 0.5,
        min_area: int = 50,
        max_detections: int = 50,
        padding: int = 5
    ) -> Tuple[List[Dict], List[np.ndarray], np.ndarray]:
        """
        ä¸€æ­¥å®Œæˆæ£€æµ‹å’Œè‰²å—æå–
        
        Args:
            image: è¾“å…¥å›¾åƒ
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            min_area: æœ€å°è‰²å—é¢ç§¯
            max_detections: æœ€å¤§æ£€æµ‹æ•°é‡
            padding: è‰²å—æå–æ—¶çš„è¾¹ç•Œæ‰©å±•
            
        Returns:
            Tuple[List[Dict], List[np.ndarray], np.ndarray]: 
                (æ£€æµ‹ç»“æœ, è‰²å—å›¾åƒåˆ—è¡¨, æ ‡æ³¨åçš„å›¾åƒ)
        """
        # æ£€æµ‹è‰²å—
        detections = self.detect_blocks(
            image, confidence_threshold, min_area, max_detections
        )
        
        # æå–è‰²å—
        color_blocks = self.extract_color_blocks(image, detections, padding)
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾åƒ
        annotated_image = self.visualize_detections(image, detections)
        
        return detections, color_blocks, annotated_image


# ===== å‘åå…¼å®¹çš„å‡½æ•°æ¥å£ï¼ˆå·²å¼ƒç”¨ï¼‰ =====

def load_yolo_block_model(model_path: str = None) -> YOLO:
    """
    åŠ è½½ç”¨äºè‰²å—æ£€æµ‹çš„YOLOæ¨¡å‹
    
    Args:
        model_path: YOLOæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º core/block_detection/weights/best.pt
        
    Returns:
        YOLOæ¨¡å‹å®ä¾‹
        
    Raises:
        FileNotFoundError: å½“æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æ—¶
    """
    warnings.warn(
        "load_yolo_block_model å‡½æ•°å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ YOLOBlockDetector ç±»",
        DeprecationWarning,
        stacklevel=2
    )
    
    if model_path is None:
        # é»˜è®¤æ¨¡å‹è·¯å¾„
        model_path = "core/block_detection/weights/best.pt"
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"YOLOè‰²å—æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")
    
    print(f"æ­£åœ¨åŠ è½½YOLOè‰²å—æ£€æµ‹æ¨¡å‹: {model_path}")
    
    try:
        model = YOLO(model_path)
        print("âœ… YOLOè‰²å—æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
    except Exception as e:
        raise RuntimeError(f"åŠ è½½YOLOè‰²å—æ¨¡å‹å¤±è´¥: {str(e)}")


def detect_blocks_with_yolo(
    colorbar_image: np.ndarray,
    model: YOLO,
    confidence_threshold: float = 0.5,
    min_area: int = 50
) -> tuple[np.ndarray, list[np.ndarray], int]:
    """
    ä½¿ç”¨YOLOæ¨¡å‹æ£€æµ‹é¢œè‰²æ¡ä¸­çš„è‰²å—
    
    Args:
        colorbar_image: é¢œè‰²æ¡å›¾åƒï¼ˆBGRæ ¼å¼çš„numpyæ•°ç»„ï¼‰
        model: YOLOæ¨¡å‹å®ä¾‹
        confidence_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0)
        min_area: æœ€å°è‰²å—é¢ç§¯ï¼ˆåƒç´ æ•°ï¼‰
        
    Returns:
        tuple: (æ ‡æ³¨å›¾åƒ, è‰²å—å›¾åƒåˆ—è¡¨, æ£€æµ‹åˆ°çš„è‰²å—æ•°é‡)
    """
    warnings.warn(
        "detect_blocks_with_yolo å‡½æ•°å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ YOLOBlockDetector ç±»",
        DeprecationWarning,
        stacklevel=2
    )
    
    if colorbar_image.size == 0:
        print("âš ï¸ è¾“å…¥çš„é¢œè‰²æ¡å›¾åƒä¸ºç©º")
        return colorbar_image, [], 0
    
    print(f"ğŸ” å¼€å§‹ä½¿ç”¨YOLOæ£€æµ‹è‰²å—ï¼Œç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold}")
    
    # è¿è¡ŒYOLOæ¨ç†
    try:
        results = model(colorbar_image, verbose=False)  # verbose=False å‡å°‘è¾“å‡º
    except Exception as e:
        print(f"âŒ YOLOæ¨ç†å¤±è´¥: {str(e)}")
        return colorbar_image, [], 0
    
    # åˆ›å»ºæ ‡æ³¨å›¾åƒçš„å‰¯æœ¬
    annotated_image = colorbar_image.copy()
    color_blocks = []
    
    height, width = colorbar_image.shape[:2]
    
    # å¤„ç†æ£€æµ‹ç»“æœ
    for result in results:
        if result.boxes is None:
            continue
            
        boxes = result.boxes.cpu().numpy()
        
        for i, box in enumerate(boxes):
            confidence = float(box.conf[0])
            
            # æ ¹æ®ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤
            if confidence < confidence_threshold:
                continue
            
            # è·å–æ£€æµ‹æ¡†åæ ‡ (x1, y1, x2, y2)
            x1, y1, x2, y2 = box.xyxy[0].astype(int)
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(width, x2)
            y2 = min(height, y2)
            
            # æ£€æŸ¥é¢ç§¯æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚
            area = (x2 - x1) * (y2 - y1)
            if area < min_area:
                print(f"âš ï¸ è‰²å—é¢ç§¯ {area} å°äºæœ€å°é˜ˆå€¼ {min_area}ï¼Œè·³è¿‡")
                continue
            
            # æå–è‰²å—å›¾åƒ
            color_block = colorbar_image[y1:y2, x1:x2]
            if color_block.size > 0:
                color_blocks.append(color_block)
                
                # åœ¨æ ‡æ³¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # æ·»åŠ æ ‡ç­¾æ–‡æœ¬
                label = f"Block {len(color_blocks)}: {confidence:.2f}"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                
                # ç¡®ä¿æ ‡ç­¾ä¸ä¼šè¶…å‡ºå›¾åƒè¾¹ç•Œ
                label_y = max(y1 - 10, label_size[1])
                cv2.putText(
                    annotated_image, 
                    label, 
                    (x1, label_y),
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.5, 
                    (0, 255, 0), 
                    2
                )
    
    block_count = len(color_blocks)
    print(f"âœ… YOLOæ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {block_count} ä¸ªè‰²å—")
    
    return annotated_image, color_blocks, block_count


def convert_pil_to_opencv(pil_image: Image.Image) -> np.ndarray:
    """
    å°†PILå›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼
    
    Args:
        pil_image: PILå›¾åƒå¯¹è±¡
        
    Returns:
        np.ndarray: BGRæ ¼å¼çš„OpenCVå›¾åƒ
    """
    # è½¬æ¢ä¸ºRGB numpyæ•°ç»„
    rgb_array = np.array(pil_image)
    
    # å¦‚æœæ˜¯ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸º3é€šé“
    if len(rgb_array.shape) == 2:
        rgb_array = cv2.cvtColor(rgb_array, cv2.COLOR_GRAY2RGB)
    
    # å¦‚æœæ˜¯RGBAï¼Œå»æ‰alphaé€šé“
    elif rgb_array.shape[2] == 4:
        rgb_array = rgb_array[:, :, :3]
    
    # è½¬æ¢ä¸ºBGRæ ¼å¼ï¼ˆOpenCVæ ‡å‡†ï¼‰
    bgr_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)
    
    return bgr_array


def convert_opencv_to_pil(opencv_image: np.ndarray) -> Image.Image:
    """
    å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILæ ¼å¼
    
    Args:
        opencv_image: BGRæ ¼å¼çš„OpenCVå›¾åƒ
        
    Returns:
        Image.Image: PILå›¾åƒå¯¹è±¡
    """
    # è½¬æ¢ä¸ºRGBæ ¼å¼
    rgb_array = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)
    
    # è½¬æ¢ä¸ºPILå›¾åƒ
    pil_image = Image.fromarray(rgb_array)
    
    return pil_image